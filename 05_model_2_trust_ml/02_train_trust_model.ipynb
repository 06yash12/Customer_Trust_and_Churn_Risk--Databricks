{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90b96aa2-3fad-478a-ad7f-2e6af11bb695",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model-2: Trust Model Training\n",
    "\n",
    "This notebook trains a secondary model that predicts whether the\n",
    "primary churn model's prediction is correct.\n",
    "\n",
    "**Objective**\n",
    "- Input: Model-1 features + predictions\n",
    "- Output: Trust probability and trust decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b10c630-c0f8-4993-b7a9-9ec8a03bde96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load Model-1 predictions with features\n",
    "trust_df = spark.table(\n",
    "    \"ai_trust_catalog.churn_trust.model_1_predictions\"\n",
    ")\n",
    "\n",
    "display(trust_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6598c31-1597-45ad-8dc8-f73aaacea487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Trust Label\n",
    "\n",
    "`trust_label = 1` → Model-1 prediction is correct  \n",
    "`trust_label = 0` → Model-1 prediction is incorrect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82715fff-89ad-45c2-b9e7-610c6408af8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "trust_df = trust_df.withColumn(\n",
    "    \"trust_label\",\n",
    "    (col(\"prediction\") == col(\"label\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "trust_df.select(\"label\", \"prediction\", \"trust_label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe981d1e-2507-4ea0-8e6e-34bd589fc309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prepare Training Data\n",
    "\n",
    "We reuse the existing `features` column.\n",
    "No feature engineering or VectorAssembler is applied here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b31d6de-c54c-4b03-89d3-bf98ebbffcac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Keep only required columns\n",
    "trust_vec_df = trust_df.select(\n",
    "    \"features\",\n",
    "    \"trust_label\"\n",
    ")\n",
    "\n",
    "train_vec, val_vec = trust_vec_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce60d7f7-3eef-44d9-93be-90e3d42a25fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train Trust Model\n",
    "\n",
    "The model predicts whether Model-1's prediction can be trusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b392acb7-0499-4286-a2f2-b3674b6a7c35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Trust Model predicts correctness of Model-1\n",
    "trust_model = LogisticRegression(\n",
    "    featuresCol=\"features\",          # already exists\n",
    "    labelCol=\"trust_label\",\n",
    "    probabilityCol=\"trust_probability\",\n",
    "    predictionCol=\"trust_prediction\"\n",
    ")\n",
    "\n",
    "model_2 = trust_model.fit(train_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93414612-bbd7-4700-b7d8-6f1173878ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate Trust Model\n",
    "\n",
    "We measure how well the Trust Model predicts correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ff5f90f-a088-4992-835c-1e62e9cdfe7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "val_predictions = model_2.transform(val_vec)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"trust_label\",\n",
    "    rawPredictionCol=\"trust_probability\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "trust_auc = evaluator.evaluate(val_predictions)\n",
    "trust_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34c68d0a-517b-41d7-8cef-a1e4b9e432d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log Trust Model\n",
    "\n",
    "The trained Trust Model is logged for governance and reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb0dd7dc-625d-42c5-89fe-9f391f04a5be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# Safety check (VERY IMPORTANT)\n",
    "assert trust_auc is not None, \"trust_auc is None. Run evaluation cell before logging.\"\n",
    "\n",
    "# Use absolute experiment path (Databricks requirement)\n",
    "mlflow.set_experiment(\"/AI Trust & Risk Intelligence Platform.04_model_1_base_ml.01_train_model_1\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"trust_model_logistic_regression\"):\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"model_type\", \"logistic_regression\")\n",
    "    \n",
    "    # Log metric (now guaranteed not None)\n",
    "    mlflow.log_metric(\"trust_auc\", float(trust_auc))\n",
    "    \n",
    "    # Log Spark ML model\n",
    "    mlflow.spark.log_model(\n",
    "        model_2,\n",
    "        artifact_path=\"trust_model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "491f1ae0-2211-45bd-bdaa-1e7d5aaf25fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save Trust Predictions\n",
    "\n",
    "This table is used for inference and dashboards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503ec4ca-b594-4cc3-8378-33c531935e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trust_final_df = val_predictions.select(\n",
    "    \"features\",\n",
    "    \"trust_label\",\n",
    "    \"trust_prediction\",\n",
    "    \"trust_probability\"\n",
    ")\n",
    "\n",
    "trust_final_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\n",
    "        \"ai_trust_catalog.churn_trust.gold_ai_trust_scores\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adc6efe6-a7d9-47e3-abb5-129d869bff23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- Built correctness-based trust labels\n",
    "- Reused existing feature vectors safely\n",
    "- Trained Trust Model without schema conflicts\n",
    "- Evaluated model using ROC-AUC\n",
    "- Logged model to MLflow\n",
    "- Saved trust predictions for downstream use"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_train_trust_model",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
